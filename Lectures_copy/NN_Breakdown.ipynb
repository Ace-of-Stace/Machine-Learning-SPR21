{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sweet-router",
   "metadata": {},
   "source": [
    "# **Lecture: Neural Network, Full Breakdown**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-easter",
   "metadata": {},
   "source": [
    "## **The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data\n",
    "DATA = pd.read_csv(\"~/Data/biology/Iris.csv\")\n",
    "print(DATA.keys())\n",
    "DATA = DATA[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']]\n",
    "\n",
    "# Make an index for different binary categories .\n",
    "mapping = {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\" : 1}\n",
    "\n",
    "# Map Setosa to -1 and the two other flowers to 1.\n",
    "DATA['Species'] = [mapping[item] for item in DATA['Species']]\n",
    "\n",
    "DATA = DATA.sample(frac=1)\n",
    "\n",
    "X = DATA[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "Y = DATA[['Species']]\n",
    "\n",
    "X_train = X.iloc[ : 100] \n",
    "Y_train = Y.iloc[ : 100]\n",
    "\n",
    "X_test = X.iloc[100 : ]\n",
    "Y_test = Y.iloc[100 : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-stylus",
   "metadata": {},
   "source": [
    "## **Network Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def brain(): # Actually create \"brain\"\n",
    "    # Establish random weights.\n",
    "    W1 = 2 * np.random.rand(4,4) - 1 #First 4 is the features, then layer, layer, layer, output\n",
    "    W2 = 2 * np.random.rand(4,3) - 1\n",
    "    W3 = 2 * np.random.rand(3,1)\n",
    "    \n",
    "    return [W1, W2, W3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function.\n",
    "def sigmoid(z):\n",
    "    a = 1 / (1 + np.e ** (-z))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-presentation",
   "metadata": {},
   "source": [
    "## **Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The foward pass. \n",
    "def forward_pass(X, W1, W2, W3):\n",
    "    # Layer 1\n",
    "    z1 = np.dot(X, W1) # Left hand side of node. (Pre-activation)\n",
    "    a1 = sigmoid(z1) # Right hand side of the node. (Post-activation)\n",
    "    \n",
    "    # Layer 2\n",
    "    z2 = np.dot(a1, W2) # Left hand side of node. (Pre-activation)\n",
    "    a2 = sigmoid(z2) # Right hand side of the node. (Post-activation)\n",
    "    \n",
    "    # Layer 3\n",
    "    z3 = np.dot(a2, W3) # Left hand side of node. (Pre-activation)\n",
    "    a3 = sigmoid(z3) # Right hand side of the node. (Post-activation)\n",
    "    \n",
    "    # Returns the guess(s) for a give datum's features or for a batch of data. \n",
    "    return [z1, z2, z3, a3] #Capture unactivated values along the way and the activated value of a3\n",
    "# If i wanted a2 instead of z2, I can send it through the activation function to get it back.\n",
    "# a3 is a value I use in cost function evaluation (it's either 0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1,W2,W3 = brain()\n",
    "Forward_Pass_Output = forward_pass(X, W1, W2, W3)\n",
    "#Forward_Pass_Output #We send them through in batches, each line is a set of four unactivated features per datum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-belgium",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-principal",
   "metadata": {},
   "source": [
    "$$ \\textrm{Cost} = \\frac{1}{N} \\sum_{i=1}^N (a_{1}^{(3)} - y_i) ^ 2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cost = np.sum((Forward_Pass_Output[3] - Y) ** 2) / np.shape(Y)[1] #How to find lowest path Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cost\n",
    "# We want to cost to be 0, since it's 42, that's not great."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-convert",
   "metadata": {},
   "source": [
    "## **Back Propagation (update the weights)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-benefit",
   "metadata": {},
   "source": [
    "$$ \\textrm{Cost} = \\frac{1}{N} \\sum_{i=1}^N (a_{1}^{(3)} - y_i) ^ 2 $$\n",
    "and\n",
    "\n",
    "$$ a_{1}^{(3)} = \\sigma(z_{1}^{(3)}) $$ \n",
    "\n",
    "which is the activation in the final node. And, \n",
    "\n",
    "$$ z_{1}^{(3)} = w_{11}^{(3)} a_{1}^{(2)} + w_{21}^{(3)} a_{2}^{(2)} + w_{31}^{(3)} a_{3}^{(2)}$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$ \\textrm{Cost} = \\frac{1}{N} \\sum_{i=1}^N ( \\sigma(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}) - y_i) ^ 2 $$\n",
    "\n",
    "This last line shows us where the first weights that we will be updating will be on the cost equation. We can compute the gradient with respect to these weights to determine the \"way to head\" on the cost surface to reduce the overall error for the data or a batch of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-dakota",
   "metadata": {},
   "source": [
    "Let's take the gradient computation on step at a time.\n",
    "\n",
    "$$ \\nabla \\textrm{Cost} = \\nabla \\frac{1}{N} \\sum_{i=1}^N ( \\sigma(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}) - y_i) ^ 2 $$\n",
    "\n",
    "$$= \\frac{1}{N} \\sum_{i=1}^N \\nabla ( \\sigma(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}) - y_i) ^ 2 $$\n",
    "\n",
    "$= \\frac{1}{N} \\sum_{i=1}^N 2(\\sigma(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}) - y_i) \\\\ \\left \\langle \\sigma'(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}) a_{1}^{(2)},\n",
    "\\sigma'(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}) a_{2}^{(2)},\n",
    "\\sigma'(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)})\n",
    "a_{3}^{(2)} \\right \\rangle\\\\ $\n",
    "\n",
    "$ = \\frac{1}{N} \\sum_{i=1}^N 2(\\sigma(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}) - y_i) \\\\ \\left \\langle \\sigma'(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}),\n",
    "\\sigma'(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)}),\n",
    "\\sigma'(\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)})\n",
    " \\right \\rangle \\\\ \\langle a_{1}^{(2)}, a_{2}^{(2)}, a_{3}^{(2)} \\rangle $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-burning",
   "metadata": {},
   "source": [
    " \n",
    "Now let's simplify some of the notation by replacing, $\\color{Red}{w_{11}^{(3)}} a_{1}^{(2)} + \\color{Red}{w_{21}^{(3)}} a_{2}^{(2)} + \\color{Red}{w_{31}^{(3)}} a_{3}^{(2)} $ with $z_{1}^{(3)} $.\n",
    "\n",
    "$$ \\frac{1}{N} \\sum_{i=1}^N 2(\\sigma(z_{1}^{(3)}) - y_i) \\left \\langle \\sigma'(z_{1}^{(3)} ), \\sigma'(z_{1}^{(3)} ), \\sigma'(z_{1}^{(3)} ) \\right \\rangle \\langle a_{1}^{(2)}, a_{2}^{(2)}, a_{3}^{(2)} \\rangle $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-olive",
   "metadata": {},
   "source": [
    " \n",
    "Now so that we can see the next step, let $N = 4$. We are going to use another subscript to indicate the datum that we are on. So the final notation will be, $z_{1_i}^{(3)}$ where $i$ is the datum that we are on. So\n",
    "\n",
    "$$ \\frac{1}{4} \\sum_{i=1}^4 2(\\sigma(z_{1_i}^{(3)}) - y_i) \\color{green}{\\left \\langle \\sigma'(z_{1_i}^{(3)}), \\sigma'(z_{1_i}^{(3)}), \\sigma'(z_{1_i}^{(3)}) \\right \\rangle} \\color{blue}{\\langle a_{1_i}^{(2)}, a_{2_i}^{(2)}, a_{3_i}^{(2)} \\rangle} =$$\n",
    "\n",
    "Applying the sum to the vectors can be done term by term,\n",
    "\n",
    "$$ \\frac{1}{4} 2(\\sigma(z_{1_1}^{(3)}) - y_1) \n",
    "\\color{green}{\\left \\langle \\sigma'(z_{1_1}^{(3)}), \\sigma'(z_{1_1}^{(3)}), \\sigma'(z_{1_1}^{(3)}) \\right \\rangle}  \n",
    "\\color{blue}{\\langle a_{1_1}^{(2)}, a_{2_1}^{(2)}, a_{3_1}^{(2)} \\rangle} + \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_2}^{(3)}) - y_2) \n",
    "\\color{green}{\\left \\langle \\sigma'(z_{1_2}^{(3)}), \\sigma'(z_{1_2}^{(3)}), \\sigma'(z_{1_2}^{(3)}) \\right \\rangle}\n",
    "\\color{blue}{\\langle a_{1_2}^{(2)}, a_{2_2}^{(2)}, a_{3_2}^{(2)} \\rangle} + \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_3}^{(3)}) - y_3) \n",
    "\\color{green}{\\left \\langle \\sigma'(z_{1_3}^{(3)}), \\sigma'(z_{1_3}^{(3)}), \\sigma'(z_{1_3}^{(3)}) \\right \\rangle}\n",
    "\\color{blue}{\\langle a_{1_3}^{(2)}, a_{2_3}^{(2)}, a_{3_3}^{(2)} \\rangle} + \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_4}^{(3)}) - y_4) \n",
    "\\color{green}{\\left \\langle \\sigma'(z_{1_4}^{(3)}), \\sigma'(z_{1_4}^{(3)}), \\sigma'(z_{1_4}^{(3)}) \\right \\rangle}\n",
    "\\color{blue}{\\langle a_{1_4}^{(2)}, a_{2_4}^{(2)}, a_{3_4}^{(2)} \\rangle}$$\n",
    "\n",
    "Then we can break the sum in each of the vector positions into a dot product,\n",
    "\n",
    "$$\\left \\langle \n",
    "\\left( \\frac{2}{4} (\\sigma(z_{1_1}^{(3)}) - y_1)\\color{green}{\\sigma'(z_{1_1}^{(3)})}\\color{blue}{a_{1_1}^{(2)}} + \\frac{2}{4} (\\sigma(z_{1_2}^{(3)}) - y_2)\\color{green}{\\sigma'(z_{1_2}^{(3)})}\\color{blue}{a_{1_2}^{(2)}} + \\frac{2}{4}(\\sigma(z_{1_3}^{(3)}) - y_3)\\color{green}{\\sigma'(z_{1_3}^{(3)})}\\color{blue}{a_{1_3}^{(2)}} + \\frac{2}{4}(\\sigma(z_{1_4}^{(3)}) - y_4)\\color{green}{\\sigma'(z_{1_4}^{(3)})}\\color{blue}{a_{1_4}^{(2)}} \\right), \\\\\n",
    "\\left( \\frac{2}{4} (\\sigma(z_{1_1}^{(3)}) - y_1))\\color{green}{\\sigma'(z_{1_1}^{(3)})}\\color{blue}{a_{2_1}^{(2)}} + \\frac{2}{4} (\\sigma(z_{1_2}^{(3)}) - y_2))\\color{green}{\\sigma'(z_{1_2}^{(3)})}\\color{blue}{a_{2_2}^{(2)}} + \\frac{2}{4}(\\sigma(z_{1_3}^{(3)}) - y_3))\\color{green}{\\sigma'(z_{1_3}^{(3)})} \\color{blue}{a_{2_3}^{(2)}} + \\frac{2}{4}(\\sigma(z_{1_4}^{(3)}) - y_4))\\color{green}{\\sigma'(z_{1_4}^{(3)})}\\color{blue}{a_{2_4}^{(2)}}  \\right), \\\\\n",
    "\\left( \\frac{2}{4} (\\sigma(z_{1_1}^{(3)}) - y_1))\\color{green}{\\sigma'(z_{1_1}^{(3)})}\\color{blue}{a_{3_1}^{(2)}} + \\frac{2}{4} (\\sigma(z_{1_2}^{(3)}) - y_2))\\color{green}{\\sigma'(z_{1_2}^{(3)})} \\color{blue}{a_{3_2}^{(2)}} + \\frac{2}{4}(\\sigma(z_{1_3}^{(3)}) - y_3))\\color{green}{\\sigma'(z_{1_3}^{(3)})} \\color{blue}{a_{3_3}^{(2)}} + \\frac{2}{4}(\\sigma(z_{1_4}^{(3)}) - y_4))\\color{green}{\\sigma'(z_{1_4}^{(3)})}\\color{blue}{a_{3_4}^{(2)}}\\right)\n",
    "\\right \\rangle \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-output",
   "metadata": {},
   "source": [
    "Then we can break the sum in each of the vector positions into a dot product,\n",
    "\n",
    "$$\\left \\langle \\frac{\\delta}{\\delta \\color{Red}{w_{11}^{(3)}}}, \\frac{\\delta}{\\delta \\color{Red}{w_{21}^{(3)}}}, \\frac{\\delta}{\\delta \\color{Red}{w_{31}^{(3)}}} \\right \\rangle =\n",
    "\\color{blue}{\\sigma\\left(\\begin{pmatrix} \n",
    "z_{1_1}^{(2)} & z_{1_2}^{(2)} & z_{1_3}^{(2)} & z_{1_4}^{(2)} \\\\\n",
    "z_{2_1}^{(2)} & z_{2_2}^{(2)} & z_{2_3}^{(2)} & z_{2_4}^{(2)} \\\\\n",
    "z_{3_1}^{(2)} & z_{3_2}^{(2)} & z_{3_3}^{(2)} & z_{3_4}^{(2)} \n",
    "\\end{pmatrix}\\right)}\n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "\\frac{1}{4} 2(\\sigma(z_{1_1}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_2}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_3}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_4}^{(3)}) - y_1) \n",
    "\\end{bmatrix}\n",
    "\\color{green}\n",
    "{\\sigma'\n",
    "\\begin{pmatrix} \n",
    "z_{1_1}^{(3)} \\\\\n",
    "z_{1_2}^{(3)} \\\\ \n",
    "z_{1_3}^{(3)} \\\\\n",
    "z_{1_4}^{(3)}\n",
    "\\end{pmatrix}} =\n",
    "\\color{blue}{\\sigma\\left(\\begin{pmatrix} \n",
    "z_{1_1}^{(2)} & z_{2_1}^{(2)} & z_{3_1}^{(2)} \\\\\n",
    "z_{2_2}^{(2)} & z_{2_2}^{(2)} & z_{3_2}^{(2)} \\\\\n",
    "z_{2_3}^{(2)} & z_{2_3}^{(2)} & z_{3_3}^{(2)} \\\\\n",
    "z_{2_4}^{(2)} & z_{2_4}^{(2)} & z_{3_4}^{(2)} \n",
    "\\end{pmatrix}\\right)^ {T}} \n",
    "\\cdot\n",
    "\\begin{bmatrix} \n",
    "\\frac{1}{4} 2(\\sigma(z_{1_1}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_2}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_3}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_4}^{(3)}) - y_1) \n",
    "\\end{bmatrix}\n",
    "\\color{green}\n",
    "{\\sigma'\n",
    "\\begin{pmatrix} \n",
    "z_{1_1}^{(3)} \\\\\n",
    "z_{1_2}^{(3)} \\\\ \n",
    "z_{1_3}^{(3)} \\\\\n",
    "z_{1_4}^{(3)}\n",
    "\\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "Where,\n",
    "$$\n",
    "\\color{blue}{\\textrm{Output of the previous layer activated} = \n",
    "\\sigma\\left(\\begin{pmatrix} \n",
    "z_{1_1}^{(2)} & z_{2_1}^{(2)} & z_{3_1}^{(2)} \\\\\n",
    "z_{2_2}^{(2)} & z_{2_2}^{(2)} & z_{3_2}^{(2)} \\\\\n",
    "z_{2_3}^{(2)} & z_{2_3}^{(2)} & z_{3_3}^{(2)} \\\\\n",
    "z_{2_4}^{(2)} & z_{2_4}^{(2)} & z_{3_4}^{(2)} \n",
    "\\end{pmatrix}\\right)} \\\\ \n",
    "\\textrm{Difference between guess and target} = \n",
    "\\begin{bmatrix} \n",
    "\\frac{1}{4} 2(\\sigma(z_{1_1}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_2}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_3}^{(3)}) - y_1) \\\\\n",
    "\\frac{1}{4} 2(\\sigma(z_{1_4}^{(3)}) - y_1) \n",
    "\\end{bmatrix}\\\\\n",
    "\\color{green}{\\textrm{Derivative applied to the pre-activation final value} = \\sigma'\n",
    "\\begin{pmatrix} \n",
    "z_{1_1}^{(3)} \\\\\n",
    "z_{1_2}^{(3)} \\\\ \n",
    "z_{1_3}^{(3)} \\\\\n",
    "z_{1_4}^{(3)}\n",
    "\\end{pmatrix}}\n",
    "$$\n",
    "\n",
    "While there are many details here, the main point of note is that we have all of these pieces from the forward pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-lancaster",
   "metadata": {},
   "source": [
    "Now let's take a quick look at the next set of wights as we move our way backwards through the network. Consider again the cost surface,\n",
    "$$ \\textrm{Cost} = \\frac{1}{N} \\sum_{i=1}^N (a_{1}^{(3)} - y_i) ^ 2 $$\n",
    "\n",
    "Now let's start building the derivatives. We are going to look at this in a bit different way then we did above. In the next few lines we will find each of the composite functions that make up the Cost function. The arrow points to the derivative for each, and we can use the chain rule to build the derivative.\n",
    "\n",
    "$$\\frac{1}{N} \\sum_{i=1}^N (a_{1}^{(3)} - y_i) ^ 2 \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial a_{1}^{(3)} }} \\ \\  \\frac{2}{N} \\sum_{i=1}^N (a_{1}^{(3)} - y_i)$$\n",
    "\n",
    "$$ a_{1}^{(3)} = \\sigma(z_{1}^{(3)}) \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial z_{1}^{(3)} }} \\ \\ \\sigma'(z_{1}^{(3)}) $$ \n",
    "\n",
    "which is the activation in the final node. And, \n",
    "\n",
    "$$ z_{1}^{(3)} = w_{11}^{(3)} a_{1}^{(2)} + w_{21}^{(3)} a_{2}^{(2)} + w_{31}^{(3)} a_{3}^{(2)} \n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial a_{1}^{(2)} }} \\ \\ w_{11}^{(3)} \\\\ \n",
    "z_{1}^{(3)} = w_{11}^{(3)} a_{1}^{(2)} + w_{21}^{(3)} a_{2}^{(2)} + w_{31}^{(3)} a_{3}^{(2)} \n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial a_{2}^{(2)} }} \\ \\ w_{21}^{(3)} \\\\\n",
    "z_{1}^{(3)} = w_{11}^{(3)} a_{1}^{(2)} + w_{21}^{(3)} a_{2}^{(2)} + w_{31}^{(3)} a_{3}^{(2)} \n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial a_{3}^{(2)} }} \\ \\ w_{31}^{(3)}  $$\n",
    "\n",
    "But to move back to the weights in the layer before we need to keep building. \n",
    "\n",
    "So,\n",
    "$$\n",
    "a_{1}^{(2)} = \\sigma(z_{1}^{(2)}) \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial z_{1}^{(3)} }} \\ \\ \\sigma'(z_{1}^{(2)})  \\\\\n",
    "a_{2}^{(2)} = \\sigma(z_{2}^{(2)}) \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial z_{2}^{(3)} }} \\ \\ \\sigma'(z_{2}^{(2)}) \\\\\n",
    "a_{3}^{(2)} = \\sigma(z_{3}^{(2)}) \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial z_{3}^{(3)} }} \\ \\ \\sigma'(z_{3}^{(2)})\n",
    "$$\n",
    "\n",
    "and,\n",
    "$$\n",
    "z_{1}^{(2)} = w_{11}^{(2)} a_{1}^{(1)} + w_{21}^{(2)} a_{2}^{(1)} + w_{31}^{(2)} a_{3}^{(1)} + w_{41}^{(2)} a_{4}^{(1)}\n",
    " \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{11}^{(2)} }} \\ \\ a_{1}^{(1)} \\\\\n",
    "z_{1}^{(2)} = w_{11}^{(2)} a_{1}^{(1)} + w_{21}^{(2)} a_{2}^{(1)} + w_{31}^{(2)} a_{3}^{(1)} + w_{41}^{(2)} a_{4}^{(1)}\n",
    " \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{21}^{(2)} }} \\ \\ a_{2}^{(1)} \\\\\n",
    "z_{1}^{(2)} = w_{11}^{(2)} a_{2}^{(1)} + w_{21}^{(2)} a_{2}^{(1)} + w_{31}^{(2)} a_{3}^{(1)} + w_{41}^{(2)} a_{4}^{(1)}\n",
    " \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{31}^{(2)} }} \\ \\ a_{3}^{(1)} \\\\\n",
    "z_{1}^{(2)} = w_{11}^{(2)} a_{3}^{(1)} + w_{21}^{(2)} a_{2}^{(1)} + w_{31}^{(2)} a_{3}^{(1)} + w_{41}^{(2)} a_{4}^{(1)}\n",
    " \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{41}^{(2)} }} \\ \\ a_{4}^{(1)} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "z_{2}^{(2)} = w_{12}^{(2)} a_{1}^{(1)} + w_{22}^{(2)} a_{2}^{(1)} + w_{32}^{(2)} a_{3}^{(1)} + w_{42}^{(2)} a_{4}^{(1)}\n",
    " \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{12}^{(2)} }} \\ \\ a_{1}^{(1)} \\\\\n",
    "z_{2}^{(2)} = w_{12}^{(2)} a_{1}^{(1)} + w_{22}^{(2)} a_{2}^{(1)} + w_{32}^{(2)} a_{3}^{(1)} + w_{42}^{(2)} a_{4}^{(1)}\n",
    " \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{22}^{(2)} }} \\ \\ a_{2}^{(1)} \\\\\n",
    "z_{2}^{(2)} = w_{12}^{(2)} a_{1}^{(1)} + w_{22}^{(2)} a_{2}^{(1)} + w_{32}^{(2)} a_{3}^{(1)} + w_{42}^{(2)} a_{4}^{(1)}\n",
    " \\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{32}^{(2)} }} \\ \\ a_{3}^{(1)} \\\\\n",
    "z_{2}^{(2)} = w_{12}^{(2)} a_{1}^{(1)} + w_{22}^{(2)} a_{2}^{(1)} + w_{32}^{(2)} a_{3}^{(1)} + w_{42}^{(2)} a_{4}^{(1)} \n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{42}^{(2)} }} \\ \\ a_{4}^{(1)} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "z_{3}^{(2)} = w_{13}^{(2)} a_{1}^{(1)} + w_{23}^{(2)} a_{2}^{(1)} + w_{33}^{(2)} a_{3}^{(1)} + w_{43}^{(2)} a_{4}^{(1)}\n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{13}^{(2)} }} \\ \\ a_{1}^{(1)} \\\\\n",
    "z_{3}^{(2)} = w_{13}^{(2)} a_{1}^{(1)} + w_{23}^{(2)} a_{2}^{(1)} + w_{33}^{(2)} a_{3}^{(1)} + w_{43}^{(2)} a_{4}^{(1)}\n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{23}^{(2)} }} \\ \\ a_{2}^{(1)} \\\\\n",
    "z_{3}^{(2)} = w_{13}^{(2)} a_{1}^{(1)} + w_{23}^{(2)} a_{2}^{(1)} + w_{33}^{(2)} a_{3}^{(1)} + w_{43}^{(2)} a_{4}^{(1)}\n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{33}^{(2)} }} \\ \\ a_{3}^{(1)} \\\\\n",
    "z_{3}^{(2)} = w_{13}^{(2)} a_{1}^{(1)} + w_{23}^{(2)} a_{2}^{(1)} + w_{33}^{(2)} a_{3}^{(1)} + w_{43}^{(2)} a_{4}^{(1)}\n",
    "\\ \\ \\xrightarrow{\\frac{\\partial}{\\partial w_{43}^{(2)} }} \\ \\ a_{4}^{(1)} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-studio",
   "metadata": {},
   "source": [
    "**NOTE: The products between the scalars, vectors and matrices below are not clear. The pattern above would be needed to turn the sum to a matrix product. The following math is to showcase the pattern and the idea of what will happen in the layers that follow.** \n",
    "\n",
    "So the pieces that make up the gradient are, \n",
    "$$\n",
    "\\frac{2}{N} \\sum_{i=1}^N (a_{1}^{(3)} - y_i)\n",
    "\\sigma'(z_{1}^{(3)})\n",
    "\\langle w_{11}^{(3)}, w_{21}^{(3)}, w_{31}^{(3)} \\rangle\n",
    "\\langle \\sigma'(z_{1}^{(2)}), \\sigma'(z_{2}^{(2)}), \\sigma'(z_{3}^{(2)}) \\rangle\n",
    "\\langle a_{1}^{(1)}, a_{2}^{(1)}, a_{3}^{(1)}, a_{4}^{(1)} \\rangle\n",
    "$$\n",
    "\n",
    "And the pattern continues,\n",
    "$$\n",
    "\\frac{2}{N} \\sum_{i=1}^N (a_{1}^{(3)} - y_i)\n",
    "\\sigma'(z_{1}^{(3)})\n",
    "\\langle w_{11}^{(3)}, w_{21}^{(3)}, w_{31}^{(3)} \\rangle\n",
    "\\langle \\sigma'(z_{1}^{(2)}), \\sigma'(z_{2}^{(2)}), \\sigma'(z_{3}^{(2)}) \\rangle\n",
    "\\begin{bmatrix}\n",
    "w_{11}^{(2)} & w_{12}^{(2)} & w_{13}^{(2)} \\\\\n",
    "w_{21}^{(2)} & w_{22}^{(2)} & w_{23}^{(2)} \\\\\n",
    "w_{31}^{(2)} & w_{32}^{(2)} & w_{33}^{(2)} \\\\\n",
    "w_{41}^{(2)} & w_{42}^{(2)} & w_{43}^{(2)} \n",
    "\\end{bmatrix}\n",
    "\\langle \\sigma'(z_{1}^{(1)}), \\sigma'(z_{2}^{(1)}), \\sigma'(z_{3}^{(1)}),  \\sigma'(z_{4}^{(1)})  \\rangle\n",
    "X\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-collaboration",
   "metadata": {},
   "source": [
    "### **Gradient Structure Reference:**\n",
    "$$ \\textrm{learning rate} \\ \\color{green}{(a_{1}^{(3)} - y_i)} \n",
    "\\color{blue}{\\sigma'(z_{1}^{(3)})} \\langle a_{1}^{(2)}, a_{2}^{(2)}, a_{3}^{(2)} \\rangle\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textrm{learning rate} \\ \\color{green}{(a_{1}^{(3)} - y_i) \\sigma'(z_{1}^{(3)}) \\textrm{W3}}\n",
    "\\color{blue}{ \\langle \\sigma'(z_{1}^{(2)}), \\sigma'(z_{2}^{(2)}), \\sigma'(z_{3}^{(2)}) \\rangle}\n",
    "\\langle a_{1}^{(1)}, a_{2}^{(1)}, a_{3}^{(1)}, a_{4}^{(1)} \\rangle\n",
    "$$\n",
    "\n",
    "$$\n",
    " \\textrm{learning rate} \\ \\color{green}{(a_{1}^{(3)} - y_i) \\sigma'(z_{1}^{(3)}) \\textrm{W3}\n",
    " \\langle \\sigma'(z_{1}^{(2)}), \\sigma'(z_{2}^{(2)}), \\sigma'(z_{3}^{(2)}) \\rangle \\textrm{W2}}\n",
    "\\color{blue} {\\langle \\sigma'(z_{1}^{(1)}), \\sigma'(z_{2}^{(1)}), \\sigma'(z_{3}^{(1)}),  \\sigma'(z_{4}^{(1)}) \\rangle}\n",
    "X\n",
    "$$\n",
    "\n",
    " <p style=\"text-align: center;\"> <img src= nn_an.png width=500 alt='[img: SVM]'/>  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(X_data,learning_rate, layers, weights, error):\n",
    "    z1 = layers[0]\n",
    "    z2 = layers[1]\n",
    "    z3 = layers[2]\n",
    "    a3 = layers[3]\n",
    "    \n",
    "    W1 = weights[0]\n",
    "    W2 = weights[1]\n",
    "    W3 = weights[2]\n",
    "    \n",
    "    # Back through the node and update the weights.\n",
    "    l3_delta = error * sigmoid(z3) * (1 - sigmoid(z3))\n",
    "    W3_update = np.dot(sigmoid(z2).T, l3_delta)\n",
    "    \n",
    "    l2_error = np.dot(l3_delta, W3.T)\n",
    "    l2_delta = l2_error * sigmoid(z2) * (1 - sigmoid(z2))\n",
    "    W2_update = np.dot(sigmoid(z1).T, l2_delta)\n",
    "\n",
    "    l1_error = np.dot(l2_delta, W2.T)\n",
    "    l1_delta = l1_error * sigmoid(z1) * (1 - sigmoid(z1))\n",
    "    W1_update = np.dot(X_data.T, l1_delta)\n",
    "\n",
    "    W3 -= learning_rate * W3_update\n",
    "    W2 -= learning_rate * W2_update\n",
    "    W1 -= learning_rate * W1_update\n",
    "    \n",
    "    return [W1,W2,W3]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-intellectual",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-comparison",
   "metadata": {},
   "source": [
    "For the training we need a bit of each of the above. The steps are:\n",
    "- Loop over all training data (Each pass is an epoch)\n",
    "    - Break the data into batches.\n",
    "    - Send a batch forward through the network.\n",
    "    - Update the weights with the gradients computed above.\n",
    "    \n",
    "Things that we will need to send into the training loop:\n",
    "- the training data.\n",
    "- the target data.\n",
    "- number of epoch.\n",
    "- learning rate.\n",
    "- weights.\n",
    "- layers that we will need to make the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-heath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the brain \n",
    "W1,W2,W3 = brain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 2000\n",
    "training_features = X_train\n",
    "learning_rate = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "for e in range(epoch + 1):\n",
    "\n",
    "    layers = forward_pass(training_features, W1, W2, W3) # Forward pass.\n",
    "    error = layers[3] - Y_train # Evaluation.\n",
    "    W1,W2,W3 = back_prop(X_train, learning_rate, layers, [W1,W2,W3], error) # Back Propogation.\n",
    "    history.append([e, np.array(np.sum((layers[3] - Y_train) ** 2) / np.shape(Y_train)[1])[0]])\n",
    "    \n",
    "    # print('\\r',\"Our elevation on the cost surface (training):\", np.array(np.sum((layers[3] - Y_train) ** 2) / np.shape(Y_train)[1])[0], end=\"                          \")\n",
    "    \n",
    "history = np.array(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(history[:,0], history[:,1], marker='.' )\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-letter",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for x,y in zip(np.array(X_test.iloc[1:]),np.array(Y_test.iloc[1:])):\n",
    "    A = forward_pass(x, W1, W2, W3)\n",
    "    if np.round(A[3]) == y:\n",
    "        s += 1\n",
    "        \n",
    "A_Test = forward_pass(X_test, W1, W2, W3)\n",
    "print(\"Our elevation on the cost surface (testing):\", np.array(np.sum((A_Test[3] - Y_test) ** 2) / np.shape(Y_test)[1])[0])\n",
    "print(\"score:\", 100 * s / len(np.array(X_test.iloc[1:])),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-injection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-macintosh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-belarus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-delivery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
